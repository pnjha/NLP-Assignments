{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "14FzgCnsfo3-hFpHY-5k-tlKm4brgm6Ie",
      "authorship_tag": "ABX9TyPbdonj6oK1FLk4d8QIzMjE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnjha/NLP-Assignments/blob/master/seq2seq_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnZnhFGmZcQy",
        "colab_type": "code",
        "outputId": "b46be572-34c2-44f7-9648-0bf30adf6d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9FI5TYNZwYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le37TUcyZyfZ",
        "colab_type": "code",
        "outputId": "279cb38a-2477-4ae5-ef15-a3822841995a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wPrDHLiZ1uM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "3dd39cda-cdbc-495d-da16-bd4d5005c800"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import copy\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, LSTM, CuDNNLSTM, Input, Embedding, TimeDistributed, Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtt2DWZGZ6Zk",
        "colab_type": "code",
        "outputId": "ef84342a-1d14-4cb2-9705-aac5b4cf77ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "# lines= pd.read_table('hin.txt', names=['eng', 'mar', 'temp'])\n",
        "X = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/dev.en', names=['eng'])\n",
        "Y = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/dev.hi', names=['hin'])\n",
        "lines = pd.concat([X,Y], axis=1)\n",
        "lines.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>hin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>To extract the appendix in case of swelling in...</td>\n",
              "      <td>अपेंडिक्श में सूजन आ जाने पर अपेंडिक्श निकालने...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>Brain can also be kept sharpened by adopting s...</td>\n",
              "      <td>कुछ अच्छी आदतें डालकर भी दिमाग को तेज रखा जा स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>H . . . AIDS is not a contagious disease .</td>\n",
              "      <td>एच.आई.वी. एड्स छूत का रोग नहीं है ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Frequent fever for a month .</td>\n",
              "      <td>एक माह से लगातार बुखार आना |</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Yoganidra - the main cause of this problem is ...</td>\n",
              "      <td>योगनिद्रा - इस समस्या का मूल कारण मानसिक तनाव ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>These are the people who learn something after...</td>\n",
              "      <td>यह वे लोग होते हैं जो किसी चीज को देखकर या पढ़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>but you will also be safe from eye diseases .</td>\n",
              "      <td>बल्कि आप नेत्ररोगों से भी बचे रहेंगे ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>Popular gujarati cultural values , abundance o...</td>\n",
              "      <td>लोकप्रिय गुजराती संस्कार , शापिंग विकल्पों की ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>Among the chief reasons of blindness , catarac...</td>\n",
              "      <td>दृष्टिहीनता के मुख्य कारणों में मोतियाबिंद 55 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>Patients are administered more anesthetic medi...</td>\n",
              "      <td>मरीज को ज्यादा निश्चेतक दवा देनी पड़ती है , जिस...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   eng                                                hin\n",
              "124  To extract the appendix in case of swelling in...  अपेंडिक्श में सूजन आ जाने पर अपेंडिक्श निकालने...\n",
              "84   Brain can also be kept sharpened by adopting s...  कुछ अच्छी आदतें डालकर भी दिमाग को तेज रखा जा स...\n",
              "183         H . . . AIDS is not a contagious disease .                एच.आई.वी. एड्स छूत का रोग नहीं है ।\n",
              "163                       Frequent fever for a month .                       एक माह से लगातार बुखार आना |\n",
              "51   Yoganidra - the main cause of this problem is ...  योगनिद्रा - इस समस्या का मूल कारण मानसिक तनाव ...\n",
              "74   These are the people who learn something after...  यह वे लोग होते हैं जो किसी चीज को देखकर या पढ़...\n",
              "0        but you will also be safe from eye diseases .             बल्कि आप नेत्ररोगों से भी बचे रहेंगे ।\n",
              "365  Popular gujarati cultural values , abundance o...  लोकप्रिय गुजराती संस्कार , शापिंग विकल्पों की ...\n",
              "194  Among the chief reasons of blindness , catarac...  दृष्टिहीनता के मुख्य कारणों में मोतियाबिंद 55 ...\n",
              "140  Patients are administered more anesthetic medi...  मरीज को ज्यादा निश्चेतक दवा देनी पड़ती है , जिस..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWfSt2wKZ95V",
        "colab_type": "code",
        "outputId": "94b2953b-4a8e-44b2-9317-8f1aa1197f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(lines.shape)\n",
        "print(lines.eng.shape)\n",
        "print(lines.hin.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(401, 2)\n",
            "(401,)\n",
            "(401,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FY7dLtu05gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_data(data,append_char):\n",
        "  data = data.apply(lambda x: x.lower())\n",
        "  data = data.apply(lambda x: x.strip())\n",
        "  data = data.apply(lambda x: re.sub(\"'\", '', x))\n",
        "  exclude = set(string.punctuation) # Set of all special characters\n",
        "  data = data.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "  remove_digits = str.maketrans('', '', digits)\n",
        "  data = data.apply(lambda x: x.translate(remove_digits))\n",
        "  if append_char:\n",
        "    data = data.apply(lambda x : 'START_ '+ x + ' _END')\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccV89t8z1s3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines.eng = process_data(lines.eng,False)\n",
        "lines.hin = process_data(lines.hin,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly2rwgU-aBCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lowercase all characters\n",
        "# lines.eng=lines.eng.apply(lambda x: x.lower())\n",
        "# lines.hin=lines.hin.apply(lambda x: x.lower())\n",
        "# X.eng=X.eng.apply(lambda x: x.lower())\n",
        "# Y.hin=Y.hin.apply(lambda x: x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhJH8VVkaDI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove quotes\n",
        "# lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
        "# lines.hin=lines.hin.apply(lambda x: re.sub(\"'\", '', x))\n",
        "# X.eng=X.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
        "# Y.hin=Y.hin.apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzKsuzEsaGDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# exclude = set(string.punctuation) # Set of all special characters\n",
        "# # Remove all the special characters\n",
        "# lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "# lines.hin=lines.hin.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "# lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "# lines.hin=lines.hin.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbwmJfTQaItR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove all numbers from text\n",
        "# remove_digits = str.maketrans('', '', digits)\n",
        "# lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
        "# lines.hin = lines.hin.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-PBMqNSaSOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove extra spaces\n",
        "# lines.eng=lines.eng.apply(lambda x: x.strip())\n",
        "# lines.hin=lines.hin.apply(lambda x: x.strip())\n",
        "# lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "# lines.hin=lines.hin.apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAUbpp-paURN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add start and end tokens to target sequences\n",
        "# lines.hin = lines.hin.apply(lambda x : 'START_ '+ x + ' _END')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpT6ADANaV2s",
        "colab_type": "code",
        "outputId": "fe464eef-b401-460b-bf68-c8883b02817d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "lines.sample(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>hin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>common blindness causing diseases like catarac...</td>\n",
              "      <td>START_ कि खाने में विटामिनसी और ओमेगा तेलों व ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>you must eat two or three eggs daily in breakf...</td>\n",
              "      <td>START_ नाश्ते में रोज दो या तीन अंडे जरूर खाएँ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>from this route tourists go to pasupathinath t...</td>\n",
              "      <td>START_ इसी रूट से पर्यटक पशुपतिनाथ बाजार भी जा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>the idols built here are unique and look so li...</td>\n",
              "      <td>START_ यहाँ निर्मित मूर्तियाँ अद्वितीय हैं और ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>this city is famous for its parks  temples  mu...</td>\n",
              "      <td>START_ यह शहर अपने पार्क  मंदिरों  म्यूजियमों ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>if you have to go to toilet frequently then ta...</td>\n",
              "      <td>START_ अगर आपको बारबार लू जाना पड़ता है  तो कोन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>first of all a walk with ram babu and the jeep...</td>\n",
              "      <td>START_ सबसे पहले राम बाबू के साथ पैदल सैर और फ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>entertainment is along everytime</td>\n",
              "      <td>START_ हर वक्‍त का मनोरंजन साथ में । _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>hundreds of such small creatures live in our b...</td>\n",
              "      <td>START_ हमारे शरीर में सैकड़ों ऐसे छोटे जीव रहत...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>beside the memorial not only of rome but of en...</td>\n",
              "      <td>START_ स्मारक के साथ ही सिर्फ रोम का ही नहीं ब...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   eng                                                hin\n",
              "2    common blindness causing diseases like catarac...  START_ कि खाने में विटामिनसी और ओमेगा तेलों व ...\n",
              "9    you must eat two or three eggs daily in breakf...  START_ नाश्ते में रोज दो या तीन अंडे जरूर खाएँ...\n",
              "212  from this route tourists go to pasupathinath t...  START_ इसी रूट से पर्यटक पशुपतिनाथ बाजार भी जा...\n",
              "349  the idols built here are unique and look so li...  START_ यहाँ निर्मित मूर्तियाँ अद्वितीय हैं और ...\n",
              "372  this city is famous for its parks  temples  mu...  START_ यह शहर अपने पार्क  मंदिरों  म्यूजियमों ...\n",
              "292  if you have to go to toilet frequently then ta...  START_ अगर आपको बारबार लू जाना पड़ता है  तो कोन...\n",
              "251  first of all a walk with ram babu and the jeep...  START_ सबसे पहले राम बाबू के साथ पैदल सैर और फ...\n",
              "398                  entertainment is along everytime           START_ हर वक्‍त का मनोरंजन साथ में । _END\n",
              "160  hundreds of such small creatures live in our b...  START_ हमारे शरीर में सैकड़ों ऐसे छोटे जीव रहत...\n",
              "319  beside the memorial not only of rome but of en...  START_ स्मारक के साथ ही सिर्फ रोम का ही नहीं ब..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtjAGdU9aWlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vocabulary of English\n",
        "all_eng_words=set()\n",
        "for eng in lines.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "# Vocabulary of Hindi \n",
        "all_hindi_words=set()\n",
        "for hin in lines.hin:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB6tSeFSdUP3",
        "colab_type": "code",
        "outputId": "8d203c8a-7c85-43ef-e726-1d2f687ed0ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Max Length of source sequence\n",
        "lenght_list=[]\n",
        "for l in lines.eng:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "max_length_src"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdUd3SGYdWk1",
        "colab_type": "code",
        "outputId": "7d7f43f8-48d8-43db-9ee3-b765d0900c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Max Length of target sequence\n",
        "lenght_list=[]\n",
        "for l in lines.hin:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "max_length_tar"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJYCaxwNdZZW",
        "colab_type": "code",
        "outputId": "8d147a2d-20df-4d64-f142-89296bd8b6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1700, 1966)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ivvkSjFdbix",
        "colab_type": "code",
        "outputId": "b436f04a-d9f2-4541-b75e-75922b803bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_decoder_tokens += 1 # For zero padding\n",
        "num_decoder_tokens"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw2l6t0tdefg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6oJRLKhdiY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk-kxIHgdk0M",
        "colab_type": "code",
        "outputId": "23051e20-d319-45df-e07e-c011303716e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "lines = shuffle(lines)\n",
        "lines.head(10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>hin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>saw a dry lake in which farmers were farming</td>\n",
              "      <td>START_ सूखी झील देखी जिसमें किसान खेती कर रहे ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>do the same exercise another side also</td>\n",
              "      <td>START_ यही क्रिया दूसरी तरफ भी करें । _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>generally pure lens or its capsule becomes dim...</td>\n",
              "      <td>START_ जब साधारणतया स्वच्छ लैन्स या उसका कैपस्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>generally pap starts developing in girls after...</td>\n",
              "      <td>START_ आमतौर पर पैप लड़कियों में  साल की उम्र क...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>rome is famous worldwide for ancient monuments...</td>\n",
              "      <td>START_ प्राचीन इमारतों और उनके अवशेषों के लिए ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>i have heard  tour packages are organized to s...</td>\n",
              "      <td>START_ मैंने सुना है  ट्राइबल लाइफ दिखाने के ल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>it s a different matter that she herself reach...</td>\n",
              "      <td>START_ यह बात अलग है कि वे खुद राह भटक कर भानग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>why discrimination when all the patients are e...</td>\n",
              "      <td>START_ एक डाक्टर के लिए सभी मरीज एक से हैं फिर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>in the journey from gujarat abutting to the we...</td>\n",
              "      <td>START_ पश्‍चिमी तट से लगे हुए गुजरात से गोवा त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>the main reason of blindness is cataract which...</td>\n",
              "      <td>START_ दृष्टिहीनता का मुख्य कारण मोतियाबिंद है...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   eng                                                hin\n",
              "253      saw a dry lake in which farmers were farming   START_ सूखी झील देखी जिसमें किसान खेती कर रहे ...\n",
              "47             do the same exercise another side also          START_ यही क्रिया दूसरी तरफ भी करें । _END\n",
              "195  generally pure lens or its capsule becomes dim...  START_ जब साधारणतया स्वच्छ लैन्स या उसका कैपस्...\n",
              "121  generally pap starts developing in girls after...  START_ आमतौर पर पैप लड़कियों में  साल की उम्र क...\n",
              "311  rome is famous worldwide for ancient monuments...  START_ प्राचीन इमारतों और उनके अवशेषों के लिए ...\n",
              "261  i have heard  tour packages are organized to s...  START_ मैंने सुना है  ट्राइबल लाइफ दिखाने के ल...\n",
              "237  it s a different matter that she herself reach...  START_ यह बात अलग है कि वे खुद राह भटक कर भानग...\n",
              "182  why discrimination when all the patients are e...  START_ एक डाक्टर के लिए सभी मरीज एक से हैं फिर...\n",
              "361  in the journey from gujarat abutting to the we...  START_ पश्‍चिमी तट से लगे हुए गुजरात से गोवा त...\n",
              "188  the main reason of blindness is cataract which...  START_ दृष्टिहीनता का मुख्य कारण मोतियाबिंद है..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOfg_XYcdqfC",
        "colab_type": "code",
        "outputId": "97083b73-bbae-49e5-a982-d536e3abf1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train - Test Split\n",
        "X, y = lines.eng, lines.hin\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "l = X_train.values.tolist()\n",
        "X_train_normal = cpoy.deepcopy(X_train)\n",
        "t = []\n",
        "for item in l:\n",
        "  p = l.split()\n",
        "  reverse(p)\n",
        "  p = \" \".join(p)\n",
        "  t.append(p)\n",
        "df = pd.DataFrame({'data':t})\n",
        "X_train = df.data\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((360,), (41,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm-385GVdvyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.to_pickle('X_train_eng_hin.pkl')\n",
        "X_test.to_pickle('X_test_eng_hin.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo6fnom9d0Fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh9Qn8ueeB1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 1000\n",
        "vec_len = 200\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veg1apwVsu9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "aceb6672-2e40-404d-a299-0f27f58a03e2"
      },
      "source": [
        "# encoder_inputs = Input(shape=(None,))\n",
        "# encoder_embedding = Embedding(input_dim = num_encoder_tokens, output_dim = vec_len)(encoder_inputs)\n",
        "# encoder_dropout   = (TimeDistributed(Dropout(rate = dropout_rate)))(encoder_embedding)\n",
        "\n",
        "# encoder_LSTM = CuDNNLSTM(latent_dim, return_sequences=True)(encoder_dropout)\n",
        "# encoder_LSTM_2 = CuDNNLSTM(latent_dim, return_sequences=True)(encoder_LSTM)\n",
        "# encoder_outputs, state_h, state_c = CuDNNLSTM(latent_dim, return_state=True)(encoder_LSTM_2)\n",
        "\n",
        "# encoder_states = [state_h, state_c]\n",
        "\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EOLUWdYsxvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "# decoder_inputs = Input(shape=(None,))\n",
        "# dec_emb_layer = Embedding(num_decoder_tokens,output_dim = vec_len)\n",
        "# dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# decoder_layer_1 = CuDNNLSTM(latent_dim, return_sequences=True)(dec_emb,initial_state=encoder_states)\n",
        "# decoder_lstm = CuDNNLSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "# decoder_outputs, _, _ = decoder_lstm(decoder_layer_1)\n",
        "# decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "# decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# # Define the model that will turn\n",
        "# # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfE1rsECsx0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "26bbee7e-b081-499c-8659-3860582422fc"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtE3dHwUsx7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 64\n",
        "epochs = 80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BpSTTk0sx-w",
        "colab_type": "code",
        "outputId": "866e19af-2f0b-420a-b530-8b41b106127d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples/batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples/batch_size)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/80\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "6/5 [================================] - 12s 2s/step - loss: 7.2426 - acc: 0.0636 - val_loss: 6.6301 - val_acc: 0.0606\n",
            "Epoch 2/80\n",
            "6/5 [================================] - 1s 216ms/step - loss: 6.1675 - acc: 0.1018 - val_loss: 6.3821 - val_acc: 0.1094\n",
            "Epoch 3/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 5.9388 - acc: 0.1270 - val_loss: 6.4215 - val_acc: 0.1146\n",
            "Epoch 4/80\n",
            "6/5 [================================] - 1s 212ms/step - loss: 5.7711 - acc: 0.1375 - val_loss: 6.3962 - val_acc: 0.1212\n",
            "Epoch 5/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 5.5810 - acc: 0.1468 - val_loss: 6.4164 - val_acc: 0.1186\n",
            "Epoch 6/80\n",
            "6/5 [================================] - 1s 207ms/step - loss: 5.4231 - acc: 0.1602 - val_loss: 6.4104 - val_acc: 0.1436\n",
            "Epoch 7/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 5.3677 - acc: 0.1628 - val_loss: 6.3895 - val_acc: 0.1489\n",
            "Epoch 8/80\n",
            "6/5 [================================] - 1s 217ms/step - loss: 5.1160 - acc: 0.1902 - val_loss: 6.4273 - val_acc: 0.1555\n",
            "Epoch 9/80\n",
            "6/5 [================================] - 1s 227ms/step - loss: 5.0543 - acc: 0.1838 - val_loss: 6.3737 - val_acc: 0.1476\n",
            "Epoch 10/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 4.7880 - acc: 0.2051 - val_loss: 6.3789 - val_acc: 0.1581\n",
            "Epoch 11/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 4.6221 - acc: 0.2045 - val_loss: 6.4554 - val_acc: 0.1607\n",
            "Epoch 12/80\n",
            "6/5 [================================] - 1s 216ms/step - loss: 4.4832 - acc: 0.2183 - val_loss: 6.4261 - val_acc: 0.1673\n",
            "Epoch 13/80\n",
            "6/5 [================================] - 1s 223ms/step - loss: 4.1956 - acc: 0.2406 - val_loss: 6.6131 - val_acc: 0.1726\n",
            "Epoch 14/80\n",
            "6/5 [================================] - 1s 213ms/step - loss: 4.0815 - acc: 0.2521 - val_loss: 6.6426 - val_acc: 0.1739\n",
            "Epoch 15/80\n",
            "6/5 [================================] - 1s 224ms/step - loss: 3.8771 - acc: 0.2662 - val_loss: 6.6844 - val_acc: 0.1700\n",
            "Epoch 16/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 3.7060 - acc: 0.2903 - val_loss: 6.8129 - val_acc: 0.1700\n",
            "Epoch 17/80\n",
            "6/5 [================================] - 1s 219ms/step - loss: 3.5696 - acc: 0.3000 - val_loss: 6.7914 - val_acc: 0.1779\n",
            "Epoch 18/80\n",
            "6/5 [================================] - 1s 210ms/step - loss: 3.3159 - acc: 0.3397 - val_loss: 6.9492 - val_acc: 0.1673\n",
            "Epoch 19/80\n",
            "6/5 [================================] - 1s 211ms/step - loss: 3.0905 - acc: 0.3814 - val_loss: 6.9642 - val_acc: 0.1858\n",
            "Epoch 20/80\n",
            "6/5 [================================] - 1s 209ms/step - loss: 2.9519 - acc: 0.4233 - val_loss: 7.0909 - val_acc: 0.1818\n",
            "Epoch 21/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 2.7135 - acc: 0.4680 - val_loss: 7.0847 - val_acc: 0.1845\n",
            "Epoch 22/80\n",
            "6/5 [================================] - 1s 211ms/step - loss: 2.5623 - acc: 0.5053 - val_loss: 7.2744 - val_acc: 0.1950\n",
            "Epoch 23/80\n",
            "6/5 [================================] - 1s 219ms/step - loss: 2.4274 - acc: 0.5334 - val_loss: 7.2538 - val_acc: 0.1924\n",
            "Epoch 24/80\n",
            "6/5 [================================] - 1s 218ms/step - loss: 2.1834 - acc: 0.5961 - val_loss: 7.3178 - val_acc: 0.1976\n",
            "Epoch 25/80\n",
            "6/5 [================================] - 1s 220ms/step - loss: 2.0092 - acc: 0.6377 - val_loss: 7.3492 - val_acc: 0.1989\n",
            "Epoch 26/80\n",
            "6/5 [================================] - 1s 222ms/step - loss: 1.8384 - acc: 0.6721 - val_loss: 7.4095 - val_acc: 0.1897\n",
            "Epoch 27/80\n",
            "6/5 [================================] - 1s 211ms/step - loss: 1.6911 - acc: 0.7001 - val_loss: 7.4578 - val_acc: 0.1910\n",
            "Epoch 28/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 1.4988 - acc: 0.7430 - val_loss: 7.5048 - val_acc: 0.1924\n",
            "Epoch 29/80\n",
            "6/5 [================================] - 1s 213ms/step - loss: 1.3557 - acc: 0.7740 - val_loss: 7.5792 - val_acc: 0.1924\n",
            "Epoch 30/80\n",
            "6/5 [================================] - 1s 213ms/step - loss: 1.2382 - acc: 0.7993 - val_loss: 7.5854 - val_acc: 0.1963\n",
            "Epoch 31/80\n",
            "6/5 [================================] - 1s 218ms/step - loss: 1.1231 - acc: 0.8247 - val_loss: 7.6363 - val_acc: 0.1963\n",
            "Epoch 32/80\n",
            "6/5 [================================] - 1s 217ms/step - loss: 0.9908 - acc: 0.8488 - val_loss: 7.6317 - val_acc: 0.2016\n",
            "Epoch 33/80\n",
            "6/5 [================================] - 1s 220ms/step - loss: 0.8981 - acc: 0.8659 - val_loss: 7.7279 - val_acc: 0.1963\n",
            "Epoch 34/80\n",
            "6/5 [================================] - 1s 212ms/step - loss: 0.8446 - acc: 0.8673 - val_loss: 7.7365 - val_acc: 0.1910\n",
            "Epoch 35/80\n",
            "6/5 [================================] - 1s 218ms/step - loss: 0.6914 - acc: 0.8977 - val_loss: 7.8251 - val_acc: 0.1937\n",
            "Epoch 36/80\n",
            "6/5 [================================] - 1s 216ms/step - loss: 0.6537 - acc: 0.9032 - val_loss: 7.8606 - val_acc: 0.1924\n",
            "Epoch 37/80\n",
            "6/5 [================================] - 1s 218ms/step - loss: 0.5728 - acc: 0.9153 - val_loss: 7.9003 - val_acc: 0.1924\n",
            "Epoch 38/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 0.5160 - acc: 0.9277 - val_loss: 7.9299 - val_acc: 0.1910\n",
            "Epoch 39/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 0.4671 - acc: 0.9320 - val_loss: 7.9703 - val_acc: 0.1976\n",
            "Epoch 40/80\n",
            "6/5 [================================] - 1s 217ms/step - loss: 0.4122 - acc: 0.9363 - val_loss: 8.0107 - val_acc: 0.1963\n",
            "Epoch 41/80\n",
            "6/5 [================================] - 1s 216ms/step - loss: 0.4010 - acc: 0.9354 - val_loss: 7.9757 - val_acc: 0.1950\n",
            "Epoch 42/80\n",
            "6/5 [================================] - 1s 213ms/step - loss: 0.3701 - acc: 0.9424 - val_loss: 8.0629 - val_acc: 0.2016\n",
            "Epoch 43/80\n",
            "6/5 [================================] - 1s 217ms/step - loss: 0.3388 - acc: 0.9440 - val_loss: 8.0666 - val_acc: 0.1989\n",
            "Epoch 44/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 0.2828 - acc: 0.9500 - val_loss: 8.0943 - val_acc: 0.2016\n",
            "Epoch 45/80\n",
            "6/5 [================================] - 1s 217ms/step - loss: 0.2522 - acc: 0.9538 - val_loss: 8.1345 - val_acc: 0.1989\n",
            "Epoch 46/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 0.2363 - acc: 0.9560 - val_loss: 8.1931 - val_acc: 0.2003\n",
            "Epoch 47/80\n",
            "6/5 [================================] - 1s 211ms/step - loss: 0.2336 - acc: 0.9555 - val_loss: 8.1594 - val_acc: 0.1950\n",
            "Epoch 48/80\n",
            "6/5 [================================] - 1s 220ms/step - loss: 0.2076 - acc: 0.9593 - val_loss: 8.2260 - val_acc: 0.2055\n",
            "Epoch 49/80\n",
            "6/5 [================================] - 1s 217ms/step - loss: 0.1870 - acc: 0.9638 - val_loss: 8.2397 - val_acc: 0.1989\n",
            "Epoch 50/80\n",
            "6/5 [================================] - 1s 211ms/step - loss: 0.1699 - acc: 0.9674 - val_loss: 8.2997 - val_acc: 0.2003\n",
            "Epoch 51/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 0.1518 - acc: 0.9690 - val_loss: 8.3395 - val_acc: 0.2029\n",
            "Epoch 52/80\n",
            "6/5 [================================] - 1s 213ms/step - loss: 0.1391 - acc: 0.9738 - val_loss: 8.3812 - val_acc: 0.2016\n",
            "Epoch 53/80\n",
            "6/5 [================================] - 1s 216ms/step - loss: 0.1252 - acc: 0.9744 - val_loss: 8.4189 - val_acc: 0.2016\n",
            "Epoch 54/80\n",
            "6/5 [================================] - 1s 216ms/step - loss: 0.1422 - acc: 0.9729 - val_loss: 8.2883 - val_acc: 0.2082\n",
            "Epoch 55/80\n",
            "6/5 [================================] - 1s 222ms/step - loss: 0.1014 - acc: 0.9842 - val_loss: 8.4315 - val_acc: 0.2016\n",
            "Epoch 56/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 0.0838 - acc: 0.9868 - val_loss: 8.4717 - val_acc: 0.2042\n",
            "Epoch 57/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 0.0777 - acc: 0.9873 - val_loss: 8.5218 - val_acc: 0.2016\n",
            "Epoch 58/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 0.0677 - acc: 0.9906 - val_loss: 8.5336 - val_acc: 0.2029\n",
            "Epoch 59/80\n",
            "6/5 [================================] - 1s 223ms/step - loss: 0.0558 - acc: 0.9947 - val_loss: 8.5437 - val_acc: 0.2042\n",
            "Epoch 60/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 0.0426 - acc: 0.9971 - val_loss: 8.5805 - val_acc: 0.2108\n",
            "Epoch 61/80\n",
            "6/5 [================================] - 1s 219ms/step - loss: 0.0387 - acc: 0.9973 - val_loss: 8.6394 - val_acc: 0.1989\n",
            "Epoch 62/80\n",
            "6/5 [================================] - 1s 218ms/step - loss: 0.0766 - acc: 0.9939 - val_loss: 8.4832 - val_acc: 0.2016\n",
            "Epoch 63/80\n",
            "6/5 [================================] - 1s 222ms/step - loss: 0.0319 - acc: 0.9991 - val_loss: 8.5736 - val_acc: 0.2108\n",
            "Epoch 64/80\n",
            "6/5 [================================] - 1s 216ms/step - loss: 0.0199 - acc: 0.9994 - val_loss: 8.6095 - val_acc: 0.2095\n",
            "Epoch 65/80\n",
            "6/5 [================================] - 1s 212ms/step - loss: 0.0144 - acc: 0.9998 - val_loss: 8.6442 - val_acc: 0.2148\n",
            "Epoch 66/80\n",
            "6/5 [================================] - 1s 219ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 8.6828 - val_acc: 0.2134\n",
            "Epoch 67/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 0.0086 - acc: 0.9998 - val_loss: 8.7063 - val_acc: 0.2082\n",
            "Epoch 68/80\n",
            "6/5 [================================] - 1s 214ms/step - loss: 0.0083 - acc: 0.9999 - val_loss: 8.7306 - val_acc: 0.2121\n",
            "Epoch 69/80\n",
            "6/5 [================================] - 1s 212ms/step - loss: 0.0076 - acc: 0.9998 - val_loss: 8.7719 - val_acc: 0.2095\n",
            "Epoch 70/80\n",
            "6/5 [================================] - 1s 212ms/step - loss: 0.0305 - acc: 0.9947 - val_loss: 8.7886 - val_acc: 0.2042\n",
            "Epoch 71/80\n",
            "6/5 [================================] - 1s 212ms/step - loss: 0.0131 - acc: 0.9983 - val_loss: 8.7656 - val_acc: 0.2148\n",
            "Epoch 72/80\n",
            "6/5 [================================] - 1s 216ms/step - loss: 0.0062 - acc: 0.9991 - val_loss: 8.7983 - val_acc: 0.2042\n",
            "Epoch 73/80\n",
            "6/5 [================================] - 1s 219ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 8.8463 - val_acc: 0.2121\n",
            "Epoch 74/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 8.8779 - val_acc: 0.2108\n",
            "Epoch 75/80\n",
            "6/5 [================================] - 1s 217ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.9109 - val_acc: 0.2082\n",
            "Epoch 76/80\n",
            "6/5 [================================] - 1s 213ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.9464 - val_acc: 0.2069\n",
            "Epoch 77/80\n",
            "6/5 [================================] - 1s 215ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.9833 - val_acc: 0.2082\n",
            "Epoch 78/80\n",
            "6/5 [================================] - 1s 213ms/step - loss: 9.4189e-04 - acc: 1.0000 - val_loss: 9.0211 - val_acc: 0.2082\n",
            "Epoch 79/80\n",
            "6/5 [================================] - 1s 219ms/step - loss: 7.7301e-04 - acc: 1.0000 - val_loss: 9.0549 - val_acc: 0.2082\n",
            "Epoch 80/80\n",
            "6/5 [================================] - 1s 213ms/step - loss: 6.3623e-04 - acc: 1.0000 - val_loss: 9.0988 - val_acc: 0.2095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ba01b6b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxmbWPSqsyCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('nmt_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQEleMwjsyE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('nmt_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPjzoG5ZK1qk",
        "colab_type": "code",
        "outputId": "b5cdffc4-6514-47af-cf4a-315926309d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 1000)   1700000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 1000)   1967000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 1000), (None 8004000     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 1000), 8004000     embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 1967)   1968967     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 21,643,967\n",
            "Trainable params: 21,643,967\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stNz5hcssyIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHHCXgnvuwAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_bleu_score(actual_string, predicted_string):\n",
        "  actual_string = copy.deepcopy(actual_string)\n",
        "  predicted_string = copy.deepcopy(predicted_string)\n",
        "  reference = re.split(\"\\s\",actual_string.strip())\n",
        "  candidate = re.split(\"\\s\",predicted_string.strip())\n",
        "  smoothie = SmoothingFunction().method4\n",
        "  score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJf_w938syL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QJgNI-ysyPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RhL-BOLsySa",
        "colab_type": "code",
        "outputId": "06b53a84-d175-423f-a64d-fc42c557d3c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "print(\"bleu score: \", calculate_bleu_score(y_train[k:k+1].values[0][6:-4],decoded_sentence[:-4]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: if you keep an interest in artefacts then do look at it \n",
            "Actual Hindi Translation:  अगर आप कलाकृतियों में दिलचस्पी रखते हैं  तो उसे जरूर देखें । \n",
            "Predicted Hindi Translation:  अगर आप कलाकृतियों में दिलचस्पी रखते हैं तो उसे \n",
            "bleu score:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwR_0xhTsyVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Dkk65SsyYV",
        "colab_type": "code",
        "outputId": "7a20f000-74fe-4149-ef25-815911b22234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(val_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
        "print(\"bleu score: \", calculate_bleu_score(y_train[k:k+1].values[0][6:-4],decoded_sentence[:-4]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: frequent loose motion for a month \n",
            "Actual Hindi Translation:  एक माह से लगातार दस्त आना  \n",
            "Predicted Hindi Translation:  एक माह से लगातार बुखार आना \n",
            "bleu score:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKQH9CAzJsAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}