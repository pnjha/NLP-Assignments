{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "nlp_q4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnjha/NLP-Assignments/blob/master/nlp_q4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T8cTiXcPVlVh",
        "colab_type": "code",
        "outputId": "ebe4675b-47e3-41ec-f879-55365836bfaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.27.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.17.5)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 58.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (45.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (1.0.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "VS9QD04HVlVu",
        "colab_type": "code",
        "outputId": "610a50e2-b2e6-4cfb-abc5-84efcbe254b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "import unicodedata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import *\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import copy\n",
        "import math\n",
        "import seaborn as sns; sns.set()\n",
        "import keras as keras\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import RandomUniform\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Input, Embedding, TimeDistributed, Flatten, Dropout, Activation, dot, concatenate, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXYXqlDlXDn6",
        "colab_type": "code",
        "outputId": "bab18051-42bb-47ff-f035-bb55585dd3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-alpha0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdP2oiBXXScN",
        "colab_type": "code",
        "outputId": "a487876d-fb67-4e9a-f4c4-f60e59c782af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5Hm_SC9XToD",
        "colab_type": "code",
        "outputId": "88e441a0-f3af-4a88-b42c-335ba4bcfa17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "X = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.en', names=['src'])\n",
        "Y_in = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.hi', names=['dest_in'])\n",
        "Y_out = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.hi', names=['dest_out'])\n",
        "lines = pd.concat([X[:100],Y_in[:100],Y_out[:100]], axis=1)\n",
        "print(len(lines))\n",
        "# lines = shuffle(lines)\n",
        "lines.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>dest_in</th>\n",
              "      <th>dest_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Lymph nodes are connected to lymph arteries an...</td>\n",
              "      <td>लसीका ग्रन्थियाँ लसीका धमनियों द्वारा एक दूसरे...</td>\n",
              "      <td>लसीका ग्रन्थियाँ लसीका धमनियों द्वारा एक दूसरे...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The blindness caused by the black cataract can...</td>\n",
              "      <td>काले मोतियाबिंद से होने वाली अधंता अंधता को रो...</td>\n",
              "      <td>काले मोतियाबिंद से होने वाली अधंता अंधता को रो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Cyst or swelling on breast or any other part o...</td>\n",
              "      <td>स्तन पर या शरीर में अन्य कहीं गाँठ या सूजन ।</td>\n",
              "      <td>स्तन पर या शरीर में अन्य कहीं गाँठ या सूजन ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Details of some important symptoms are given b...</td>\n",
              "      <td>कुछ महत्वपूर्ण लक्षणों का विवरण नीचे दिया जा र...</td>\n",
              "      <td>कुछ महत्वपूर्ण लक्षणों का विवरण नीचे दिया जा र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Shadowiness in seeing things nearby or at a di...</td>\n",
              "      <td>दूर अथवा नजदीक देखने में धुंधलापन सर में दर्द ...</td>\n",
              "      <td>दूर अथवा नजदीक देखने में धुंधलापन सर में दर्द ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>When the extra pressure is more in the eyes .</td>\n",
              "      <td>जब आँखों में अतिरिक्त दबाव ज्यादा हो ।</td>\n",
              "      <td>जब आँखों में अतिरिक्त दबाव ज्यादा हो ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>We progress towards development and getting ri...</td>\n",
              "      <td>जैसे-जैसे हम विकास की ओर अग्रसर हो रहे है एवं ...</td>\n",
              "      <td>जैसे-जैसे हम विकास की ओर अग्रसर हो रहे है एवं ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>No stitches are applied in the S . . . . -LRB-...</td>\n",
              "      <td>S.I.C.S ( Small Incision Cataract Surgry ) विध...</td>\n",
              "      <td>S.I.C.S ( Small Incision Cataract Surgry ) विध...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In black cataract the eye nerves dilapidates g...</td>\n",
              "      <td>काला मोतियाबिंद में नेत्र तंत्रिका धीरे -धीरे ...</td>\n",
              "      <td>काला मोतियाबिंद में नेत्र तंत्रिका धीरे -धीरे ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Nyctalopia may occur due to lack of vitamin-A .</td>\n",
              "      <td>विटामिन-ए की कमी से रतौंधी हो सकती है ।</td>\n",
              "      <td>विटामिन-ए की कमी से रतौंधी हो सकती है ।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  src  ...                                           dest_out\n",
              "98  Lymph nodes are connected to lymph arteries an...  ...  लसीका ग्रन्थियाँ लसीका धमनियों द्वारा एक दूसरे...\n",
              "8   The blindness caused by the black cataract can...  ...  काले मोतियाबिंद से होने वाली अधंता अंधता को रो...\n",
              "80  Cyst or swelling on breast or any other part o...  ...       स्तन पर या शरीर में अन्य कहीं गाँठ या सूजन ।\n",
              "77  Details of some important symptoms are given b...  ...  कुछ महत्वपूर्ण लक्षणों का विवरण नीचे दिया जा र...\n",
              "50  Shadowiness in seeing things nearby or at a di...  ...  दूर अथवा नजदीक देखने में धुंधलापन सर में दर्द ...\n",
              "9       When the extra pressure is more in the eyes .  ...             जब आँखों में अतिरिक्त दबाव ज्यादा हो ।\n",
              "55  We progress towards development and getting ri...  ...  जैसे-जैसे हम विकास की ओर अग्रसर हो रहे है एवं ...\n",
              "6   No stitches are applied in the S . . . . -LRB-...  ...  S.I.C.S ( Small Incision Cataract Surgry ) विध...\n",
              "7   In black cataract the eye nerves dilapidates g...  ...  काला मोतियाबिंद में नेत्र तंत्रिका धीरे -धीरे ...\n",
              "20    Nyctalopia may occur due to lack of vitamin-A .  ...            विटामिन-ए की कमी से रतौंधी हो सकती है ।\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UG0m8dw0VlV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_data(data,append_char):\n",
        "    data = data.apply(lambda x: x.lower())\n",
        "    data = data.apply(lambda x: x.strip())\n",
        "    data = data.apply(lambda x: re.sub(\"'\", '', x))\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    data = data.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    data = data.apply(lambda x: x.translate(remove_digits))\n",
        "    if append_char == 1:\n",
        "        data = data.apply(lambda x : '<sos> '+ x)\n",
        "    elif append_char == 2:\n",
        "        data = data.apply(lambda x : x + ' <eos>')\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IyxG22xlVlWI",
        "colab_type": "code",
        "outputId": "730adae9-a439-42c7-be35-885f431e5192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "lines.src = process_data(lines.src,0)\n",
        "lines.dest_in = process_data(lines.dest_in,1)\n",
        "lines.dest_out = process_data(lines.dest_out,2)\n",
        "lines.src.sample(10),lines.dest_in.sample(10),lines.dest_out.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79           any wound that do not heal in enough time \n",
              " 52             cancer is a lifestyle generated disease \n",
              " 5     in the s     lrb small incision cataract surge...\n",
              " 37    when the rays of light do not fall on the reti...\n",
              " 51          cylindrical glasses have to be worn always \n",
              " 65    in cancer cells multiply by itself and ignores...\n",
              " 46    headache  heaviness in the eyes  problem in re...\n",
              " 90    the need is to increase the knowledge about it...\n",
              " 32    about  to  percent of children become blind wi...\n",
              " 88    show these to the doctor if these symptoms sta...\n",
              " Name: src, dtype: object,\n",
              " 60    <sos> देश के सभी आंकडों का आंकलन कर देखा गया ह...\n",
              " 44    <sos> क्लास में विद्यार्थी श्यामपट के काफी नजद...\n",
              " 49    <sos> यदि कोई रोशनी की किरण आँख के पर्दे के आग...\n",
              " 23                   <sos> कम रोशनी में दिखाई देता है ।\n",
              " 78    <sos> गुर्दे में ऑक्जेलेट पत्थरी रही हो तो आगे...\n",
              " 64                    <sos> कैंसर एक बीमारी का नाम है ।\n",
              " 12    <sos> अंदर का दबाव बढ़ता जाता है और नेत्र तंत्...\n",
              " 87    <sos> अतः इन्हें देखते ही कैंसर नहीं मान लेना ...\n",
              " 67    <sos> कोशिका एक गिल्टी या घाव का रूप ले लेती ह...\n",
              " 77    <sos> कुछ महत्वपूर्ण लक्षणों का विवरण नीचे दिय...\n",
              " Name: dest_in, dtype: object,\n",
              " 19    विटामिनए की कमी खसरे तथा कुपोषण की स्थिति में ...\n",
              " 37    जब प्रकाश की किरणें दृष्टि पटल  रेटिना  पर नही...\n",
              " 70    सामान्यतः सुसाध्य ट्यूमरों को शल्यचिकित्सा द्व...\n",
              " 72    असाध्य ट्यूमर निकट के ऊतकों और अंगों को नष्ट क...\n",
              " 75    कैंसर का पता चलते ही इसका इलाज आरम्भ किया जा स...\n",
              " 86    वैसे  ऐसे लक्षण केवल कैंसर के कारण ही पैदा नही...\n",
              " 90    आवश्यकता है  इसके बारे में जानकारी बढ़ाने तथा ह...\n",
              " 96    ग्रीवा का कैंसर स्त्रियों में होने वाला एक आम ...\n",
              " 94    सामान्य परीक्षणों द्वारा कुछ प्रकार के कैंसर र...\n",
              " 51         सिलिंडरिकल ग्लासेस को हमेशा पहनना है । <eos>\n",
              " Name: dest_out, dtype: object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hctS3GJPVlXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y_in, y_out = lines.src.values, lines.dest_in.values, lines.dest_out.values \n",
        "X_train, X_test, y_in_train, y_in_test, y_out_train, y_out_test = train_test_split(X, y_in, y_out, test_size = 0.2,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eHA43VgCVlX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "src_tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "data_src = src_tokenizer.texts_to_sequences(X_train)\n",
        "data_src = tf.keras.preprocessing.sequence.pad_sequences(data_src,padding='post')\n",
        "\n",
        "# print(src_tokenizer.word_index)\n",
        "# print(data_src)\n",
        "# print(len(data_src[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nR6cH5nCVlYa",
        "colab_type": "code",
        "outputId": "e4280d17-51e0-4046-8a14-452cdf5a4a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dest_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "\n",
        "dest_tokenizer.fit_on_texts(y_in_train)\n",
        "dest_tokenizer.fit_on_texts(y_out_train)\n",
        "\n",
        "data_dest_in = dest_tokenizer.texts_to_sequences(y_in_train)\n",
        "data_dest_in = tf.keras.preprocessing.sequence.pad_sequences(data_dest_in,padding='post')\n",
        "\n",
        "data_dest_out = dest_tokenizer.texts_to_sequences(y_out_train)\n",
        "data_dest_out = tf.keras.preprocessing.sequence.pad_sequences(data_dest_out,padding='post')\n",
        "\n",
        "print(data_dest_in.shape)\n",
        "print(data_dest_out.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 40)\n",
            "(80, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MbfbVZJ2VlYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "        self.lstm_2 = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, sequence, states):\n",
        "        embed = self.embedding(sequence)\n",
        "        output, state_h, state_c = self.lstm_1(embed, initial_state=states)\n",
        "        output, state_h, state_c = self.lstm_2(output, initial_state=[state_h,state_c])\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        return (tf.zeros([batch_size, self.lstm_size]),\n",
        "                tf.zeros([batch_size, self.lstm_size]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQfpoKcUwkJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuongAttention(tf.keras.Model):\n",
        "    def __init__(self, lstm_size):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.wa = tf.keras.layers.Dense(lstm_size)\n",
        "\n",
        "    def call(self, decoder_output, encoder_output):\n",
        "        score = tf.matmul(decoder_output, self.wa(encoder_output), transpose_b=True)\n",
        "        attention_weights = tf.nn.softmax(score, axis=2)\n",
        "        context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUfY-c-NqQ-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuongAttentionDot(tf.keras.Model):\n",
        "    def __init__(self, lstm_size):\n",
        "        super(LuongAttentionDot, self).__init__()\n",
        "        self.wa = tf.keras.layers.Dense(lstm_size)\n",
        "\n",
        "    def call(self, decoder_output, encoder_output):\n",
        "        # Dot score: h_t (dot) Wa (dot) h_s\n",
        "        # encoder_output shape: (batch_size, max_len, lstm_size)\n",
        "        # decoder_output shape: (batch_size, 1, lstm_size)\n",
        "        # score will have shape: (batch_size, 1, max_len)\n",
        "        score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
        "        attention_weights = tf.nn.softmax(score, axis=2)\n",
        "        context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0bCsxa0dobg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, lstm_size):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(lstm_size)\n",
        "    self.W2 = tf.keras.layers.Dense(lstm_size)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, decoder_output, encoder_output):\n",
        "    \n",
        "    score = self.V(tf.nn.tanh(self.W1(decoder_output) + self.W2(encoder_output)))\n",
        "    score = tf.transpose(score,perm=[0,2,1])\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(score, axis=2)\n",
        "    context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WNCnftgdVlYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, lstm_size, attn_type):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        if attn_type == 'LuongAttention':\n",
        "          self.attention = LuongAttention(lstm_size)\n",
        "        elif attn_type == 'LuongAttentionDot':\n",
        "          self.attention = LuongAttentionDot(lstm_size)\n",
        "        elif attn_type == 'BahdanauAttention':\n",
        "          self.attention = BahdanauAttention(lstm_size)\n",
        "\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "        self.wc = tf.keras.layers.Dense(lstm_size, activation='tanh')\n",
        "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, sequence, state, encoder_output):\n",
        "\n",
        "        embed = self.embedding(sequence)\n",
        "        \n",
        "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
        "        context, alignment = self.attention(lstm_out, encoder_output)\n",
        "        lstm_out = tf.concat([tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
        "\n",
        "        lstm_out = self.wc(lstm_out)\n",
        "        logits = self.ws(lstm_out)\n",
        "\n",
        "        return logits, state_h, state_c, alignment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME_nQdjnYfAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "EMBEDDING_SIZE = 256\n",
        "LSTM_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SQRK3GwjVlYd",
        "colab_type": "code",
        "outputId": "41b69217-f693-45c5-e5ca-6fba5b8867b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data_src, data_dest_in, data_dest_out))\n",
        "dataset = dataset.shuffle(20).batch(BATCH_SIZE)\n",
        "print(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 42), (None, 40), (None, 40)), types: (tf.int32, tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fNmuoKfFVlYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(attn_type):\n",
        "  src_vocab_size = len(src_tokenizer.word_index) + 1\n",
        "  dest_vocab_size = len(dest_tokenizer.word_index) + 1\n",
        "\n",
        "  encoder = Encoder(src_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
        "  decoder = Decoder(dest_vocab_size, EMBEDDING_SIZE, LSTM_SIZE,attn_type)\n",
        "  return encoder, decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7KWUdSdhVlYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JuoO4txGVlY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tyva_R0LVlY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model,source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
        "    loss = 0\n",
        "    encoder = model[\"encoder\"]\n",
        "    decoder = model[\"decoder\"]\n",
        "    with tf.GradientTape() as tape:\n",
        "        en_outputs = encoder(source_seq, en_initial_states)\n",
        "        en_states = en_outputs[1:]\n",
        "        de_state_h, de_state_c = en_states\n",
        "        \n",
        "        # We need to create a loop to iterate through the target sequences\n",
        "        for i in range(target_seq_out.shape[1]):\n",
        "            # Input to the decoder must have shape of (batch_size, length)\n",
        "            # so we need to expand one dimension\n",
        "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
        "            logit, de_state_h, de_state_c, _ = decoder(decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
        "            \n",
        "            # The loss is now accumulated through the whole batch\n",
        "            loss += loss_func(target_seq_out[:, i], logit)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss / target_seq_out.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "I42H8EXJVlY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model,test_source_text):\n",
        "    test_source_seq = src_tokenizer.texts_to_sequences([test_source_text])\n",
        "\n",
        "    encoder = model[\"encoder\"]\n",
        "    decoder = model[\"decoder\"]\n",
        "\n",
        "    en_initial_states = encoder.init_states(1)\n",
        "    en_outputs = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[dest_tokenizer.word_index['<sos>']]])\n",
        "    de_state_h, de_state_c = en_outputs[1:]\n",
        "    out_words = []\n",
        "    alignments = []\n",
        "\n",
        "    while True:\n",
        "        de_output, de_state_h, de_state_c, alignment = decoder(\n",
        "            de_input, (de_state_h, de_state_c), en_outputs[0])\n",
        "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
        "        try:\n",
        "          out_words.append(dest_tokenizer.index_word[de_input.numpy()[0][0]])\n",
        "        except:\n",
        "          out_words.append('<unk>')\n",
        "        alignments.append(alignment.numpy())\n",
        "\n",
        "        if out_words[-1] == '<eos>' or len(out_words) >= 50:\n",
        "            break\n",
        "\n",
        "    out_words = ' '.join(out_words)\n",
        "    return np.array(alignments), out_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LsPjpaeTVlZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(attn_type,NUM_EPOCHS):\n",
        "  encoder, decoder = get_model(attn_type)\n",
        "  model = {\"encoder\":encoder,\"decoder\":decoder}\n",
        "  loss_list = []\n",
        "  ep_list = []\n",
        "  for e in range(NUM_EPOCHS):\n",
        "      en_initial_states = encoder.init_states(BATCH_SIZE)\n",
        "\n",
        "      for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "          loss = train_step(model, source_seq, target_seq_in,target_seq_out, en_initial_states)\n",
        "      \n",
        "      ep_list.append(e+1)\n",
        "      loss_list.append(loss.numpy())\n",
        "      print('Epoch {} Loss {:.8f}'.format(e + 1, loss.numpy()))\n",
        "  return encoder, decoder, loss_list, ep_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V68sDlbyVlZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_bleu_score(actual_string, predicted_string):\n",
        "    actual_string = copy.deepcopy(actual_string)\n",
        "    predicted_string = copy.deepcopy(predicted_string)\n",
        "    reference = re.split(\"\\s\",actual_string.strip())\n",
        "    candidate = re.split(\"\\s\",predicted_string.strip())\n",
        "    try:\n",
        "      reference.remove('<eos>')\n",
        "      candidate.remove('<sos>')\n",
        "    except:\n",
        "      pass\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io7wptcmxdfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(xlist,ylist,xname,yname):\n",
        "  x = np.array(xlist)\n",
        "  y = np.array(ylist)\n",
        "  d = {xname: x, yname: y}\n",
        "  data = pd.DataFrame(d)\n",
        "  sns.lineplot(x=xname, y=yname,data = data)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PkvNOsmdCu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction(X,y,model):\n",
        "  for index,line in enumerate(X):\n",
        "    alignment, output = predict(model,line)\n",
        "    print(\"source: \",line)\n",
        "    print(\"actual: \",y[index])\n",
        "    print(\"predicted: \",output)\n",
        "    # print(\"BLEU Score: \",calculate_bleu_score(output,y[index]))\n",
        "    ax = sns.heatmap(alignment[:,0,0,:],linewidths=.2,cmap=\"YlGnBu\")\n",
        "    # print(type(alignment))\n",
        "    # print(alignment[:,0,0,:])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--YEfvR4x_7X",
        "colab_type": "code",
        "outputId": "99179e22-3e63-489a-a9d2-07347449a2ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "attn_type = 'BahdanauAttention'\n",
        "# attn_type = 'LuongAttentionDot'\n",
        "# attn_type = 'LuongAttention'\n",
        "NUM_EPOCHS = 500\n",
        "encoder, decoder, loss_list,epoch_list = train_model(attn_type,NUM_EPOCHS)\n",
        "plot_graph(epoch_list,loss_list,\"Epochs\",\"Loss\")\n",
        "model = {\"encoder\":encoder,\"decoder\":decoder}\n",
        "# get_prediction(X_test,y_in_test)\n",
        "get_prediction(X_train,y_in_train, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f068c254c18>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f068c083908>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f068c0f5cc0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "Epoch 1 Loss 2.29289508\n",
            "Epoch 2 Loss 2.13742495\n",
            "Epoch 3 Loss 2.06380534\n",
            "Epoch 4 Loss 2.02519774\n",
            "Epoch 5 Loss 1.95744324\n",
            "Epoch 6 Loss 1.89152110\n",
            "Epoch 7 Loss 1.82661378\n",
            "Epoch 8 Loss 1.75454676\n",
            "Epoch 9 Loss 1.68535638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4S00hyf3oTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}