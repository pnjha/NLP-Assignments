{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp_q4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnjha/NLP-Assignments/blob/master/nlp_q4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-03-04T07:08:33.743Z"
        },
        "colab_type": "code",
        "id": "T8cTiXcPVlVh",
        "outputId": "921e7fc7-049e-49fe-b01e-60f4855a1c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.17.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.27.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 20.3MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 28.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.34.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (45.1.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab_type": "code",
        "id": "VS9QD04HVlVu",
        "outputId": "cd973d1e-f28e-4934-8ccf-c74ada27495a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "import unicodedata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib.pyplot import *\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import copy\n",
        "import math\n",
        "import seaborn as sns; sns.set()\n",
        "import keras as keras\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import RandomUniform\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Input, Embedding, TimeDistributed, Flatten, Dropout, Activation, dot, concatenate, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tXYXqlDlXDn6",
        "outputId": "606a6e26-be1f-432b-f372-78b890855a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-alpha0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tdP2oiBXXScN",
        "outputId": "08d18bce-6ee9-4d12-a416-9e8b33e067b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R5Hm_SC9XToD",
        "outputId": "95b66ca0-d74b-450d-8bad-72af098baaa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "X = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.en', names=['src'])\n",
        "Y_in = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.hi', names=['dest_in'])\n",
        "Y_out = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.hi', names=['dest_out'])\n",
        "lines = pd.concat([X[:20],Y_in[:20],Y_out[:20]], axis=1)\n",
        "print(len(lines))\n",
        "# lines = shuffle(lines)\n",
        "lines.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>dest_in</th>\n",
              "      <th>dest_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Main symptoms on appearance of which a patient...</td>\n",
              "      <td>प्रमुख लक्षण जिनके प्रकट होने पर रोगी को डॉक्ट...</td>\n",
              "      <td>प्रमुख लक्षण जिनके प्रकट होने पर रोगी को डॉक्ट...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lens is fitted in the capsular bag .</td>\n",
              "      <td>कैपस्यूलर बैग में लैन्स फिट किया जाता है ।</td>\n",
              "      <td>कैपस्यूलर बैग में लैन्स फिट किया जाता है ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Internal pressure keeps on increasing and the ...</td>\n",
              "      <td>अंदर का दबाव बढ़ता जाता है और नेत्र तंत्रिका न...</td>\n",
              "      <td>अंदर का दबाव बढ़ता जाता है और नेत्र तंत्रिका न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>In the S . . . . -LRB- Small Incision Cataract...</td>\n",
              "      <td>S.I.C.S ( Small Incision Cataract Surgry ) विध...</td>\n",
              "      <td>S.I.C.S ( Small Incision Cataract Surgry ) विध...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In black cataract the eye nerves dilapidates g...</td>\n",
              "      <td>काला मोतियाबिंद में नेत्र तंत्रिका धीरे -धीरे ...</td>\n",
              "      <td>काला मोतियाबिंद में नेत्र तंत्रिका धीरे -धीरे ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The blindness caused by the black cataract can...</td>\n",
              "      <td>काले मोतियाबिंद से होने वाली अधंता अंधता को रो...</td>\n",
              "      <td>काले मोतियाबिंद से होने वाली अधंता अंधता को रो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>We will check the eye nerves with special lens...</td>\n",
              "      <td>विशेष लैन्स या यंत्र के द्वारा नेत्र तंत्रिका ...</td>\n",
              "      <td>विशेष लैन्स या यंत्र के द्वारा नेत्र तंत्रिका ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Complete lens capsule is taken out in the meth...</td>\n",
              "      <td>इन्ट्रा कैनसूलर कैटरेक्ट एक्सट्रेक्शन ( Intra ...</td>\n",
              "      <td>इन्ट्रा कैनसूलर कैटरेक्ट एक्सट्रेक्शन ( Intra ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In most of the patients the part of the water ...</td>\n",
              "      <td>अधिकांश मरीजों में आँख से पानी जाने का हिस्सा ...</td>\n",
              "      <td>अधिकांश मरीजों में आँख से पानी जाने का हिस्सा ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>When the extra pressure is more in the eyes .</td>\n",
              "      <td>जब आँखों में अतिरिक्त दबाव ज्यादा हो ।</td>\n",
              "      <td>जब आँखों में अतिरिक्त दबाव ज्यादा हो ।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  src  ...                                           dest_out\n",
              "13  Main symptoms on appearance of which a patient...  ...  प्रमुख लक्षण जिनके प्रकट होने पर रोगी को डॉक्ट...\n",
              "4                Lens is fitted in the capsular bag .  ...         कैपस्यूलर बैग में लैन्स फिट किया जाता है ।\n",
              "12  Internal pressure keeps on increasing and the ...  ...  अंदर का दबाव बढ़ता जाता है और नेत्र तंत्रिका न...\n",
              "5   In the S . . . . -LRB- Small Incision Cataract...  ...  S.I.C.S ( Small Incision Cataract Surgry ) विध...\n",
              "7   In black cataract the eye nerves dilapidates g...  ...  काला मोतियाबिंद में नेत्र तंत्रिका धीरे -धीरे ...\n",
              "8   The blindness caused by the black cataract can...  ...  काले मोतियाबिंद से होने वाली अधंता अंधता को रो...\n",
              "15  We will check the eye nerves with special lens...  ...  विशेष लैन्स या यंत्र के द्वारा नेत्र तंत्रिका ...\n",
              "1   Complete lens capsule is taken out in the meth...  ...  इन्ट्रा कैनसूलर कैटरेक्ट एक्सट्रेक्शन ( Intra ...\n",
              "11  In most of the patients the part of the water ...  ...  अधिकांश मरीजों में आँख से पानी जाने का हिस्सा ...\n",
              "9       When the extra pressure is more in the eyes .  ...             जब आँखों में अतिरिक्त दबाव ज्यादा हो ।\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UG0m8dw0VlV_",
        "colab": {}
      },
      "source": [
        "def process_data(data,append_char):\n",
        "    data = data.apply(lambda x: x.lower())\n",
        "    data = data.apply(lambda x: x.strip())\n",
        "    data = data.apply(lambda x: re.sub(\"'\", '', x))\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    data = data.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    data = data.apply(lambda x: x.translate(remove_digits))\n",
        "    if append_char == 1:\n",
        "        data = data.apply(lambda x : '<sos> '+ x)\n",
        "    elif append_char == 2:\n",
        "        data = data.apply(lambda x : x + ' <eos>')\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IyxG22xlVlWI",
        "outputId": "eaaef94c-f403-4647-8fc4-8028c4b23e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "lines.src = process_data(lines.src,0)\n",
        "lines.dest_in = process_data(lines.dest_in,1)\n",
        "lines.dest_out = process_data(lines.dest_out,2)\n",
        "lines.src.sample(10),lines.dest_in.sample(10),lines.dest_out.sample(10)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11    in most of the patients the part of the water ...\n",
              " 8     the blindness caused by the black cataract can...\n",
              " 12    internal pressure keeps on increasing and the ...\n",
              " 2     during operation lens is implanted at front of...\n",
              " 7     in black cataract the eye nerves dilapidates g...\n",
              " 0     the treatment of cataract is possible through ...\n",
              " 3     in the extra capsular cataract method  the par...\n",
              " 6     no stitches are applied in the s     lrb small...\n",
              " 1     complete lens capsule is taken out in the meth...\n",
              " 10    if somebody suffers from black cataract in the...\n",
              " Name: src, dtype: object,\n",
              " 18    <sos> sos विटामिनए की कमी से कॉर्नियल कमजोर तथ...\n",
              " 14    <sos> sos रोशनी मे इंद्र धनुष के समान रंगीन गो...\n",
              " 10    <sos> sos यदि परिवार में किसी को काला मोतियाबि...\n",
              " 5     <sos> sos sics  small incision cataract surgry...\n",
              " 4     <sos> sos कैपस्यूलर बैग में लैन्स फिट किया जात...\n",
              " 3     <sos> sos इक्स्ट्रा कैनसूलर कैटरेक्ट एक्सट्रेक...\n",
              " 9      <sos> sos जब आँखों में अतिरिक्त दबाव ज्यादा हो ।\n",
              " 1     <sos> sos इन्ट्रा कैनसूलर कैटरेक्ट एक्सट्रेक्श...\n",
              " 17    <sos> sos एक विशेष लैन्स द्वारा पानी के बाहर ज...\n",
              " 16    <sos> sos फिल्ड टेस्ट जिसमें सामने देखते हुए स...\n",
              " Name: dest_in, dtype: object,\n",
              " 9      जब आँखों में अतिरिक्त दबाव ज्यादा हो । eos <eos>\n",
              " 14    रोशनी मे इंद्र धनुष के समान रंगीन गोले दिखाई द...\n",
              " 2     ऑपरेशन के दौरान लैन्स प्रत्यारोपण आँख के अगले ...\n",
              " 11    अधिकांश मरीजों में आँख से पानी जाने का हिस्सा ...\n",
              " 15    विशेष लैन्स या यंत्र के द्वारा नेत्र तंत्रिका ...\n",
              " 6     sics  small incision cataract surgry  विधि में...\n",
              " 8     काले मोतियाबिंद से होने वाली अधंता अंधता को रो...\n",
              " 16    फिल्ड टेस्ट जिसमें सामने देखते हुए साइड की चीज...\n",
              " 12    अंदर का दबाव बढ़ता जाता है और नेत्र तंत्रिका न...\n",
              " 3     इक्स्ट्रा कैनसूलर कैटरेक्ट एक्सट्रेक्शन विधि म...\n",
              " Name: dest_out, dtype: object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hctS3GJPVlXq",
        "colab": {}
      },
      "source": [
        "X, y_in, y_out = lines.src.values, lines.dest_in.values, lines.dest_out.values \n",
        "X_train, X_test, y_in_train, y_in_test, y_out_train, y_out_test = train_test_split(X, y_in, y_out, test_size = 0.2,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eHA43VgCVlX2",
        "colab": {}
      },
      "source": [
        "src_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "src_tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "data_src = src_tokenizer.texts_to_sequences(X_train)\n",
        "data_src = tf.keras.preprocessing.sequence.pad_sequences(data_src,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nR6cH5nCVlYa",
        "outputId": "856f178f-4471-463c-ec0a-5d129cdfcbc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dest_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "\n",
        "dest_tokenizer.fit_on_texts(y_in_train)\n",
        "dest_tokenizer.fit_on_texts(y_out_train)\n",
        "\n",
        "data_dest_in = dest_tokenizer.texts_to_sequences(y_in_train)\n",
        "data_dest_in = tf.keras.preprocessing.sequence.pad_sequences(data_dest_in,padding='post')\n",
        "\n",
        "data_dest_out = dest_tokenizer.texts_to_sequences(y_out_train)\n",
        "data_dest_out = tf.keras.preprocessing.sequence.pad_sequences(data_dest_out,padding='post')\n",
        "\n",
        "print(data_dest_in.shape)\n",
        "print(data_dest_out.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 39)\n",
            "(16, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MbfbVZJ2VlYj",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "        self.lstm_2 = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, sequence, states):\n",
        "        embed = self.embedding(sequence)\n",
        "        output, state_h, state_c = self.lstm_1(embed, initial_state=states)\n",
        "        output, state_h, state_c = self.lstm_2(output, initial_state=[state_h,state_c])\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        return (tf.zeros([batch_size, self.lstm_size]),\n",
        "                tf.zeros([batch_size, self.lstm_size]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zQfpoKcUwkJ3",
        "colab": {}
      },
      "source": [
        "class LuongAttention(tf.keras.Model):\n",
        "    def __init__(self, lstm_size):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.wa = tf.keras.layers.Dense(lstm_size)\n",
        "\n",
        "    def call(self, decoder_output, encoder_output):\n",
        "        score = tf.matmul(decoder_output, self.wa(encoder_output), transpose_b=True)\n",
        "        attention_weights = tf.nn.softmax(score, axis=2)\n",
        "        context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lUfY-c-NqQ-_",
        "colab": {}
      },
      "source": [
        "class LuongAttentionDot(tf.keras.Model):\n",
        "    def __init__(self, lstm_size):\n",
        "        super(LuongAttentionDot, self).__init__()\n",
        "        self.wa = tf.keras.layers.Dense(lstm_size)\n",
        "\n",
        "    def call(self, decoder_output, encoder_output):\n",
        "        score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
        "        attention_weights = tf.nn.softmax(score, axis=2)\n",
        "        context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_0bCsxa0dobg",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, lstm_size):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(lstm_size)\n",
        "    self.W2 = tf.keras.layers.Dense(lstm_size)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, decoder_output, encoder_output):\n",
        "    \n",
        "    score = self.V(tf.nn.tanh(self.W1(decoder_output) + self.W2(encoder_output)))\n",
        "    score = tf.transpose(score,perm=[0,2,1])\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(score, axis=2)\n",
        "    context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CPHzL0Lhu_eT",
        "colab": {}
      },
      "source": [
        "class BahdanauAttentionCoverage(tf.keras.Model):\n",
        "  def __init__(self, lstm_size):\n",
        "    super(BahdanauAttentionCoverage, self).__init__()\n",
        "    self.coverage = None\n",
        "    self.W1 = tf.keras.layers.Dense(lstm_size,name=\"W1\")\n",
        "    self.W2 = tf.keras.layers.Dense(lstm_size,name=\"W2\")\n",
        "    self.W3 = tf.keras.layers.Dense(lstm_size,name=\"W3\")\n",
        "    self.W4 = tf.keras.layers.Dense(lstm_size,name=\"W4\")\n",
        "    self.W5 = tf.keras.layers.Dense(lstm_size,name=\"W5\")\n",
        "    self.W6 = tf.keras.layers.Dense(lstm_size,name=\"W6\")\n",
        "    self.W7 = tf.keras.layers.Dense(lstm_size,name=\"W7\")\n",
        "    self.V1 = tf.keras.layers.Dense(1,name=\"V1\")\n",
        "    self.V2 = tf.keras.layers.Dense(1,name=\"V2\")\n",
        "\n",
        "  def call(self, decoder_output, encoder_output):\n",
        "    \n",
        "    if self.coverage is None: \n",
        "      self.coverage = decoder_output\n",
        "\n",
        "    score = self.V1(tf.nn.tanh(self.W1(decoder_output) + self.W2(encoder_output) + self.W3(self.coverage)))\n",
        "    score = tf.transpose(score,perm=[0,2,1])\n",
        "    \n",
        "    self.coverage = self.V1(tf.nn.tanh(self.W4(decoder_output) + self.W5(encoder_output) + self.W6(self.coverage)))\n",
        "    self.coverage = tf.reshape(self.coverage, tf.shape(encoder_output).numpy())\n",
        "    # print(self.coverage.shape, decoder_output.shape, encoder_output.shape)\n",
        "\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=2)\n",
        "    context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "    # print(score.shape,decoder_output.shape,encoder_output.shape,attention_weights.shape,context_vector.shape)\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WNCnftgdVlYp",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, lstm_size, attn_type):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        if attn_type == 'LuongAttention':\n",
        "          self.attention = LuongAttention(lstm_size)\n",
        "        elif attn_type == 'LuongAttentionDot':\n",
        "          self.attention = LuongAttentionDot(lstm_size)\n",
        "        elif attn_type == 'BahdanauAttention':\n",
        "          self.attention = BahdanauAttention(lstm_size)\n",
        "        elif attn_type == 'BahdanauAttentionCoverage':\n",
        "          self.attention = BahdanauAttentionCoverage(lstm_size)\n",
        "        \n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "        self.lstm_2 = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "        self.wc = tf.keras.layers.Dense(lstm_size, activation='tanh')\n",
        "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, sequence, state, encoder_output):\n",
        "\n",
        "        embed = self.embedding(sequence)\n",
        "        \n",
        "        lstm_out, state_h, state_c = self.lstm_1(embed, initial_state=state)\n",
        "        lstm_out, state_h, state_c = self.lstm_2(lstm_out, initial_state=[state_h,state_c])\n",
        "        context, alignment = self.attention(lstm_out, encoder_output)\n",
        "\n",
        "        lstm_out = tf.concat([tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
        "        lstm_out = self.wc(lstm_out)\n",
        "        logits = self.ws(lstm_out)\n",
        "\n",
        "        return logits, state_h, state_c, alignment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R5MZyUaIWir_",
        "outputId": "eb1a4a86-14c5-489e-eb28-2135811af7f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "print(c.shape)\n",
        "# repeat(c, repeats=[1, 3], axis=1) "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ME_nQdjnYfAk",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 2\n",
        "EMBEDDING_SIZE = 256\n",
        "LSTM_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SQRK3GwjVlYd",
        "outputId": "a16758d2-2830-4831-ff5f-5e9cb60156e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data_src, data_dest_in, data_dest_out))\n",
        "dataset = dataset.shuffle(20).batch(BATCH_SIZE)\n",
        "print(dataset)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 31), (None, 39), (None, 39)), types: (tf.int32, tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fNmuoKfFVlYu",
        "colab": {}
      },
      "source": [
        "def get_model(attn_type):\n",
        "  src_vocab_size = len(src_tokenizer.word_index) + 1\n",
        "  dest_vocab_size = len(dest_tokenizer.word_index) + 1\n",
        "\n",
        "  encoder = Encoder(src_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
        "  decoder = Decoder(dest_vocab_size, EMBEDDING_SIZE, LSTM_SIZE,attn_type)\n",
        "  return encoder, decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7KWUdSdhVlYy",
        "colab": {}
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JuoO4txGVlY3",
        "colab": {}
      },
      "source": [
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "# optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01,initial_accumulator_value=0.2)\n",
        "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.03)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyva_R0LVlY6",
        "colab": {}
      },
      "source": [
        "def train_step(model,source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
        "    loss = 0\n",
        "    encoder = model[\"encoder\"]\n",
        "    decoder = model[\"decoder\"]\n",
        "    with tf.GradientTape() as tape:\n",
        "        en_outputs = encoder(source_seq, en_initial_states)\n",
        "        en_states = en_outputs[1:]\n",
        "        de_state_h, de_state_c = en_states\n",
        "        \n",
        "        for i in range(target_seq_out.shape[1]):          \n",
        "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
        "            logit, de_state_h, de_state_c, _ = decoder(decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
        "            loss += loss_func(target_seq_out[:, i], logit)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss / target_seq_out.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LsPjpaeTVlZC",
        "colab": {}
      },
      "source": [
        "def train_model(attn_type,NUM_EPOCHS):\n",
        "  encoder, decoder = get_model(attn_type)\n",
        "  model = {\"encoder\":encoder,\"decoder\":decoder}\n",
        "  loss_list = []\n",
        "  ep_list = []\n",
        "\n",
        "  en_initial_states = encoder.init_states(BATCH_SIZE)\n",
        "  for e in range(NUM_EPOCHS):\n",
        "  \n",
        "      for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "          loss = train_step(model, source_seq, target_seq_in,target_seq_out, en_initial_states)\n",
        "      \n",
        "      ep_list.append(e+1)\n",
        "      loss_list.append(loss.numpy())\n",
        "      print('Epoch {} Loss {:.8f}'.format(e + 1, loss.numpy()))\n",
        "  return encoder, decoder, loss_list, ep_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I42H8EXJVlY_",
        "colab": {}
      },
      "source": [
        "def predict(model,test_source_text):\n",
        "    \n",
        "    encoder = model[\"encoder\"]\n",
        "    decoder = model[\"decoder\"]\n",
        "    src_tokenizer = model[\"src_tokenizer\"]\n",
        "    dest_tokenizer = model[\"dest_tokenizer\"]\n",
        "\n",
        "    test_source_seq = src_tokenizer.texts_to_sequences([test_source_text])\n",
        "\n",
        "    en_initial_states = encoder.init_states(1)\n",
        "    en_outputs = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[dest_tokenizer.word_index['<sos>']]])\n",
        "    de_state_h, de_state_c = en_outputs[1:]\n",
        "    out_words = []\n",
        "    alignments = []\n",
        "\n",
        "    while True:\n",
        "        de_output, de_state_h, de_state_c, alignment = decoder(de_input, (de_state_h, de_state_c), en_outputs[0])\n",
        "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
        "        try:\n",
        "          out_words.append(dest_tokenizer.index_word[de_input.numpy()[0][0]])\n",
        "        except:\n",
        "          out_words.append('<unk>')\n",
        "        alignments.append(alignment.numpy())\n",
        "\n",
        "        if out_words[-1] == '<eos>' or len(out_words) >= 50:\n",
        "            break\n",
        "\n",
        "    out_words = ' '.join(out_words)\n",
        "    return np.array(alignments), out_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V68sDlbyVlZk",
        "colab": {}
      },
      "source": [
        "def calculate_bleu_score(actual_string, predicted_string):\n",
        "    actual_string = copy.deepcopy(actual_string)\n",
        "    predicted_string = copy.deepcopy(predicted_string)\n",
        "    reference = re.split(\"\\s\",actual_string.strip())\n",
        "    candidate = re.split(\"\\s\",predicted_string.strip())\n",
        "    try:\n",
        "      reference.remove('<eos>')\n",
        "      candidate.remove('<sos>')\n",
        "    except:\n",
        "      pass\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "io7wptcmxdfy",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_graph(xlist,ylist,xname,yname):\n",
        "  x = np.array(xlist)\n",
        "  y = np.array(ylist)\n",
        "  d = {xname: x, yname: y}\n",
        "  data = pd.DataFrame(d)\n",
        "  sns.lineplot(x=xname, y=yname,data = data)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1PkvNOsmdCu2",
        "colab": {}
      },
      "source": [
        "def get_prediction(X,y,model):\n",
        "  for index,line in enumerate(X):\n",
        "    alignment, output = predict(model,line)\n",
        "    print(\"source: \",line)\n",
        "    print(\"actual: \",y[index])\n",
        "    print(\"predicted: \",output)\n",
        "    print(\"BLEU Score: \",calculate_bleu_score(output,y[index]))\n",
        "    ax = sns.heatmap(alignment[:,0,0,:],linewidths=.2,cmap=\"YlGnBu\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--YEfvR4x_7X",
        "outputId": "2be05f52-be2f-4245-a0e5-6454926b5a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "# attn_type = 'BahdanauAttention'\n",
        "# attn_type = 'LuongAttentionDot'\n",
        "attn_type = 'LuongAttention'\n",
        "# attn_type = 'BahdanauAttentionCoverage'\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "encoder, decoder, loss_list,epoch_list = train_model(attn_type,NUM_EPOCHS)\n",
        "model = {\"encoder\":encoder, \"decoder\":decoder, \"attn_type\":attn_type, \"src_tokenizer\":src_tokenizer, \"dest_tokenizer\":dest_tokenizer}\n",
        "# model = { \"attn_type\":attn_type, \"src_tokenizer\":src_tokenizer, \"dest_tokenizer\":dest_tokenizer}\n",
        "\n",
        "plot_graph(epoch_list,loss_list,\"Epochs\",\"Loss\")\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f31300b9080>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f31300b9e10>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f3143e52e80>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f3143dd15c0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "Epoch 1 Loss 1.79245889\n",
            "Epoch 2 Loss 2.09652448\n",
            "Epoch 3 Loss 1.70728028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEMCAYAAADqG+D0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xl3Ufj8nORp-",
        "outputId": "cde525a0-8c87-45cb-c5c4-fdb3de3068d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "get_prediction(X_test,y_in_test,model)\n",
        "# get_prediction(X_train,y_in_train, model)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-473e7b035b3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_in_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# get_prediction(X_train,y_in_train, model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-eb39c2a4a27c>\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(X, y, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0malignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"source: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"actual: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-e45773212b2f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, test_source_text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_source_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decoder\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msrc_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"src_tokenizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'encoder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z4S00hyf3oTt",
        "colab": {}
      },
      "source": [
        "import dill\n",
        "import pickle\n",
        "import weakref\n",
        "\n",
        "nameoffile = \"q4\"\n",
        "with open(nameoffile, \"wb\") as dill_file:\n",
        "    dill.dump(model, dill_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzUDUjW7hyR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = {}\n",
        "with open(nameoffile, \"rb\") as dill_file:\n",
        "  model = dill.load(dill_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy4VxzTredqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "880b1ab3-d050-4845-aaa1-059d4fe39f4c"
      },
      "source": [
        "print(model['attn_type'])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LuongAttention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGXXEsdlo1Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}