{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "nlp_11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnjha/NLP-Assignments/blob/master/nlp_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T8cTiXcPVlVh",
        "colab_type": "code",
        "outputId": "ebe4675b-47e3-41ec-f879-55365836bfaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.27.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.17.5)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 58.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (45.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (1.0.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "VS9QD04HVlVu",
        "colab_type": "code",
        "outputId": "6c6d0bc5-2607-45bb-dcb1-477cade23bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "import unicodedata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import *\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import copy\n",
        "import math\n",
        "import seaborn as sns; sns.set()\n",
        "import keras as keras\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import RandomUniform\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Input, Embedding, TimeDistributed, Flatten, Dropout, Activation, dot, concatenate, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXYXqlDlXDn6",
        "colab_type": "code",
        "outputId": "c6935db3-833e-4cb6-c079-522dc8c29695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-alpha0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdP2oiBXXScN",
        "colab_type": "code",
        "outputId": "7da91a34-b63a-4c81-fad0-7496ab0b5470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5Hm_SC9XToD",
        "colab_type": "code",
        "outputId": "3db9afaf-ccfd-4d4f-c17a-32b862b07e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "X = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.en', names=['src'])\n",
        "Y_in = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.hi', names=['dest_in'])\n",
        "Y_out = pd.read_table('./NLA S20 - Assignment 2 Data/enghin/train.hi', names=['dest_out'])\n",
        "lines = pd.concat([X[:100],Y_in[:100],Y_out[:100]], axis=1)\n",
        "print(len(lines))\n",
        "# lines = shuffle(lines)\n",
        "lines.sample(10)"
      ],
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>dest_in</th>\n",
              "      <th>dest_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>When the rays of light do not fall on the reti...</td>\n",
              "      <td>जब प्रकाश की किरणें दृष्टि पटल ( रेटिना ) पर न...</td>\n",
              "      <td>जब प्रकाश की किरणें दृष्टि पटल ( रेटिना ) पर न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Any wound that do not heal in enough time .</td>\n",
              "      <td>कोई भी घाव जो काफी समय से भरता नहीं हो ।</td>\n",
              "      <td>कोई भी घाव जो काफी समय से भरता नहीं हो ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>If a ray of light can not concentrate at the f...</td>\n",
              "      <td>यदि कोई रोशनी की किरण आँख के पर्दे के आगे या प...</td>\n",
              "      <td>यदि कोई रोशनी की किरण आँख के पर्दे के आगे या प...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>To save eyes from diseases it is necessary to ...</td>\n",
              "      <td>रोगों से आँखों के बचाव के लिये Environmental s...</td>\n",
              "      <td>रोगों से आँखों के बचाव के लिये Environmental s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>If somebody suffers from black cataract in the...</td>\n",
              "      <td>यदि परिवार में किसी को काला मोतियाबिंद हो ।</td>\n",
              "      <td>यदि परिवार में किसी को काला मोतियाबिंद हो ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Details of some important symptoms are given b...</td>\n",
              "      <td>कुछ महत्वपूर्ण लक्षणों का विवरण नीचे दिया जा र...</td>\n",
              "      <td>कुछ महत्वपूर्ण लक्षणों का विवरण नीचे दिया जा र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Main symptoms on appearance of which a patient...</td>\n",
              "      <td>प्रमुख लक्षण जिनके प्रकट होने पर रोगी को डॉक्ट...</td>\n",
              "      <td>प्रमुख लक्षण जिनके प्रकट होने पर रोगी को डॉक्ट...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>It is visible in dim light .</td>\n",
              "      <td>कम रोशनी में दिखाई देता है ।</td>\n",
              "      <td>कम रोशनी में दिखाई देता है ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>Cell takes the form of a cyst or wound , and d...</td>\n",
              "      <td>कोशिका एक गिल्टी या घाव का रूप ले लेती है , और...</td>\n",
              "      <td>कोशिका एक गिल्टी या घाव का रूप ले लेती है , और...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Fungus is also a kind of being that lives in o...</td>\n",
              "      <td>फंगस भी हमारे शरीर में रहने वाला ऐसा एक जीव है...</td>\n",
              "      <td>फंगस भी हमारे शरीर में रहने वाला ऐसा एक जीव है...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  src  ...                                           dest_out\n",
              "37  When the rays of light do not fall on the reti...  ...  जब प्रकाश की किरणें दृष्टि पटल ( रेटिना ) पर न...\n",
              "79        Any wound that do not heal in enough time .  ...           कोई भी घाव जो काफी समय से भरता नहीं हो ।\n",
              "49  If a ray of light can not concentrate at the f...  ...  यदि कोई रोशनी की किरण आँख के पर्दे के आगे या प...\n",
              "34  To save eyes from diseases it is necessary to ...  ...  रोगों से आँखों के बचाव के लिये Environmental s...\n",
              "10  If somebody suffers from black cataract in the...  ...        यदि परिवार में किसी को काला मोतियाबिंद हो ।\n",
              "77  Details of some important symptoms are given b...  ...  कुछ महत्वपूर्ण लक्षणों का विवरण नीचे दिया जा र...\n",
              "13  Main symptoms on appearance of which a patient...  ...  प्रमुख लक्षण जिनके प्रकट होने पर रोगी को डॉक्ट...\n",
              "23                       It is visible in dim light .  ...                       कम रोशनी में दिखाई देता है ।\n",
              "67  Cell takes the form of a cyst or wound , and d...  ...  कोशिका एक गिल्टी या घाव का रूप ले लेती है , और...\n",
              "39  Fungus is also a kind of being that lives in o...  ...  फंगस भी हमारे शरीर में रहने वाला ऐसा एक जीव है...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UG0m8dw0VlV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_data(data,append_char):\n",
        "    data = data.apply(lambda x: x.lower())\n",
        "    data = data.apply(lambda x: x.strip())\n",
        "    data = data.apply(lambda x: re.sub(\"'\", '', x))\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    data = data.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    data = data.apply(lambda x: x.translate(remove_digits))\n",
        "    if append_char == 1:\n",
        "        data = data.apply(lambda x : '<sos> '+ x)\n",
        "    elif append_char == 2:\n",
        "        data = data.apply(lambda x : x + ' <eos>')\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IyxG22xlVlWI",
        "colab_type": "code",
        "outputId": "5b568188-e399-48dc-bc8b-8ec83fa80c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "lines.src = process_data(lines.src,0)\n",
        "lines.dest_in = process_data(lines.dest_in,1)\n",
        "lines.dest_out = process_data(lines.dest_out,2)\n",
        "lines.src.sample(10),lines.dest_in.sample(10),lines.dest_out.sample(10)"
      ],
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40    fungus creates its abode in damped places like...\n",
              " 69    although each of the disease is different from...\n",
              " 95    doctors can find out cancer diseases of mouth ...\n",
              " 71                         difficult tumors are cancer \n",
              " 2     during operation lens is implanted at front of...\n",
              " 61    it is between  and  percent among the rural wo...\n",
              " 78    if there is an oxalate stone in the kidney wha...\n",
              " 66            cells also reach other parts of the body \n",
              " 75    the treatment of cancer can start as soon as i...\n",
              " 83    pain in swallowing food or during toilet  cont...\n",
              " Name: src, dtype: object,\n",
              " 60    <sos> देश के सभी आंकडों का आंकलन कर देखा गया ह...\n",
              " 31    <sos> रूबेला के कारण होने वाले कन्जानाईटल कैटर...\n",
              " 18    <sos> विटामिनए की कमी से कॉर्नियल कमजोर तथा घा...\n",
              " 9          <sos> जब आँखों में अतिरिक्त दबाव ज्यादा हो ।\n",
              " 46    <sos> सिर दर्द  आँखों में भारीपन  पढ़ने में पर...\n",
              " 72    <sos> असाध्य ट्यूमर निकट के ऊतकों और अंगों को ...\n",
              " 52    <sos> कैंसर एक जीवन शैली से उत्पन्न होने वाली ...\n",
              " 41                    <sos> जिसे ओनिकोमाइसिस कहते हैं ।\n",
              " 4      <sos> कैपस्यूलर बैग में लैन्स फिट किया जाता है ।\n",
              " 10    <sos> यदि परिवार में किसी को काला मोतियाबिंद हो ।\n",
              " Name: dest_in, dtype: object,\n",
              " 82    लगातार काफी समय तक खाँसी आना या आवाज भारी होना...\n",
              " 9          जब आँखों में अतिरिक्त दबाव ज्यादा हो । <eos>\n",
              " 22    खसरे के समय व बाद में विटामिनए की मांग का अधिक...\n",
              " 68       कैंसर  से अधिक बीमारीयों का एक समूह है । <eos>\n",
              " 95    किसी चिन्ह के प्रकट होने के पहले ही चिकित्सक म...\n",
              " 40    फंगस नमी वाली जगह जैसे हमारे पैर के अंगूठे के ...\n",
              " 24                    स्वेत पटल सूखा हो जाता है । <eos>\n",
              " 63                                 कैंसर क्या है  <eos>\n",
              " 14    रोशनी मे इंद्र धनुष के समान रंगीन गोले दिखाई द...\n",
              " 79       कोई भी घाव जो काफी समय से भरता नहीं हो । <eos>\n",
              " Name: dest_out, dtype: object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 446
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hctS3GJPVlXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y_in, y_out = lines.src.values, lines.dest_in.values, lines.dest_out.values \n",
        "X_train, X_test, y_in_train, y_in_test, y_out_train, y_out_test = train_test_split(X, y_in, y_out, test_size = 0.2,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eHA43VgCVlX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "src_tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "data_src = src_tokenizer.texts_to_sequences(X_train)\n",
        "data_src = tf.keras.preprocessing.sequence.pad_sequences(data_src,padding='post')\n",
        "\n",
        "# print(src_tokenizer.word_index)\n",
        "# print(data_src)\n",
        "# print(len(data_src[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nR6cH5nCVlYa",
        "colab_type": "code",
        "outputId": "2de5241c-29b7-4acc-b852-dbe48e14ef78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dest_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "\n",
        "dest_tokenizer.fit_on_texts(y_in_train)\n",
        "dest_tokenizer.fit_on_texts(y_out_train)\n",
        "\n",
        "data_dest_in = dest_tokenizer.texts_to_sequences(y_in_train)\n",
        "data_dest_in = tf.keras.preprocessing.sequence.pad_sequences(data_dest_in,padding='post')\n",
        "\n",
        "data_dest_out = dest_tokenizer.texts_to_sequences(y_out_train)\n",
        "data_dest_out = tf.keras.preprocessing.sequence.pad_sequences(data_dest_out,padding='post')\n",
        "\n",
        "print(data_dest_in.shape)\n",
        "print(data_dest_out.shape)"
      ],
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 40)\n",
            "(80, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MbfbVZJ2VlYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "        self.lstm_2 = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, sequence, states):\n",
        "        embed = self.embedding(sequence)\n",
        "        output, state_h, state_c = self.lstm_1(embed, initial_state=states)\n",
        "        output, state_h, state_c = self.lstm_2(output, initial_state=[state_h,state_c])\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        return (tf.zeros([batch_size, self.lstm_size]),\n",
        "                tf.zeros([batch_size, self.lstm_size]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQfpoKcUwkJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuongAttention(tf.keras.Model):\n",
        "    def __init__(self, lstm_size):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.wa = tf.keras.layers.Dense(lstm_size)\n",
        "\n",
        "    def call(self, decoder_output, encoder_output):\n",
        "        score = tf.matmul(decoder_output, self.wa(encoder_output), transpose_b=True)\n",
        "        attention_weights = tf.nn.softmax(score, axis=2)\n",
        "        context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUfY-c-NqQ-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuongAttentionDot(tf.keras.Model):\n",
        "    def __init__(self, lstm_size):\n",
        "        super(LuongAttentionDot, self).__init__()\n",
        "        self.wa = tf.keras.layers.Dense(lstm_size)\n",
        "\n",
        "    def call(self, decoder_output, encoder_output):\n",
        "        # Dot score: h_t (dot) Wa (dot) h_s\n",
        "        # encoder_output shape: (batch_size, max_len, lstm_size)\n",
        "        # decoder_output shape: (batch_size, 1, lstm_size)\n",
        "        # score will have shape: (batch_size, 1, max_len)\n",
        "        score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
        "        attention_weights = tf.nn.softmax(score, axis=2)\n",
        "        context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0bCsxa0dobg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, lstm_size):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(lstm_size)\n",
        "    self.W2 = tf.keras.layers.Dense(lstm_size)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, decoder_output, encoder_output):\n",
        "    \n",
        "    score = self.V(tf.nn.tanh(self.W1(decoder_output) + self.W2(encoder_output)))\n",
        "    score = tf.transpose(score,perm=[0,2,1])\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    context_vector = tf.matmul(attention_weights, encoder_output)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WNCnftgdVlYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, lstm_size, attn_type):\n",
        "        super(Decoder, self).__init__()\n",
        "        if attn_type == 'LuongAttention':\n",
        "          self.attention = LuongAttention(lstm_size)\n",
        "        elif attn_type == 'LuongAttentionDot':\n",
        "          self.attention = LuongAttentionDot(lstm_size)\n",
        "        elif attn_type == 'BahdanauAttention':\n",
        "          self.attention = BahdanauAttention(lstm_size)\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "        self.wc = tf.keras.layers.Dense(lstm_size, activation='tanh')\n",
        "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, sequence, state, encoder_output):\n",
        "        # Remember that the input to the decoder\n",
        "        # is now a batch of one-word sequences,\n",
        "        # which means that its shape is (batch_size, 1)\n",
        "        embed = self.embedding(sequence)\n",
        "        \n",
        "        # Therefore, the lstm_out has shape (batch_size, 1, lstm_size)\n",
        "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
        "        context, alignment = self.attention(lstm_out, encoder_output)\n",
        "        lstm_out = tf.concat([tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
        "        \n",
        "        # lstm_out now has shape (batch_size, lstm_size)\n",
        "        lstm_out = self.wc(lstm_out)\n",
        "        \n",
        "        # Finally, it is converted back to vocabulary space: (batch_size, vocab_size)\n",
        "        logits = self.ws(lstm_out)\n",
        "\n",
        "        return logits, state_h, state_c, alignment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME_nQdjnYfAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "EMBEDDING_SIZE = 256\n",
        "LSTM_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SQRK3GwjVlYd",
        "colab_type": "code",
        "outputId": "00d17afa-72fe-4f8c-9768-83dc212e181e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data_src, data_dest_in, data_dest_out))\n",
        "dataset = dataset.shuffle(20).batch(BATCH_SIZE)\n",
        "print(dataset)"
      ],
      "execution_count": 456,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 42), (None, 40), (None, 40)), types: (tf.int32, tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fNmuoKfFVlYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(attn_type):\n",
        "  src_vocab_size = len(src_tokenizer.word_index) + 1\n",
        "  dest_vocab_size = len(dest_tokenizer.word_index) + 1\n",
        "\n",
        "  encoder = Encoder(src_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
        "  decoder = Decoder(dest_vocab_size, EMBEDDING_SIZE, LSTM_SIZE,attn_type)\n",
        "  return encoder, decoder\n",
        "\n",
        "# encoder, decoder = get_model()\n",
        "# initial_states = encoder.init_states(1)\n",
        "# encoder_outputs = encoder(tf.constant([[1, 2, 3]]), initial_states)\n",
        "# decoder_outputs = decoder(tf.constant([[1, 2, 3]]), encoder_outputs[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7KWUdSdhVlYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JuoO4txGVlY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tyva_R0LVlY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(model,source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
        "    loss = 0\n",
        "    encoder = model[\"encoder\"]\n",
        "    decoder = model[\"decoder\"]\n",
        "    with tf.GradientTape() as tape:\n",
        "        en_outputs = encoder(source_seq, en_initial_states)\n",
        "        en_states = en_outputs[1:]\n",
        "        de_state_h, de_state_c = en_states\n",
        "        \n",
        "        # We need to create a loop to iterate through the target sequences\n",
        "        for i in range(target_seq_out.shape[1]):\n",
        "            # Input to the decoder must have shape of (batch_size, length)\n",
        "            # so we need to expand one dimension\n",
        "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
        "            logit, de_state_h, de_state_c, _ = decoder(decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
        "            \n",
        "            # The loss is now accumulated through the whole batch\n",
        "            loss += loss_func(target_seq_out[:, i], logit)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss / target_seq_out.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "I42H8EXJVlY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model,test_source_text):\n",
        "    test_source_seq = src_tokenizer.texts_to_sequences([test_source_text])\n",
        "\n",
        "    encoder = model[\"encoder\"]\n",
        "    decoder = model[\"decoder\"]\n",
        "\n",
        "    en_initial_states = encoder.init_states(1)\n",
        "    en_outputs = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[dest_tokenizer.word_index['<sos>']]])\n",
        "    de_state_h, de_state_c = en_outputs[1:]\n",
        "    out_words = []\n",
        "    alignments = []\n",
        "\n",
        "    while True:\n",
        "        de_output, de_state_h, de_state_c, alignment = decoder(\n",
        "            de_input, (de_state_h, de_state_c), en_outputs[0])\n",
        "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
        "        try:\n",
        "          out_words.append(dest_tokenizer.index_word[de_input.numpy()[0][0]])\n",
        "        except:\n",
        "          out_words.append('<unk>')\n",
        "        alignments.append(alignment.numpy())\n",
        "\n",
        "        if out_words[-1] == '<eos>' or len(out_words) >= 50:\n",
        "            break\n",
        "\n",
        "    out_words = ' '.join(out_words)\n",
        "    return np.array(alignments), out_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LsPjpaeTVlZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(attn_type,NUM_EPOCHS):\n",
        "  encoder, decoder = get_model(attn_type)\n",
        "  model = {\"encoder\":encoder,\"decoder\":decoder}\n",
        "  loss_list = []\n",
        "  ep_list = []\n",
        "  for e in range(NUM_EPOCHS):\n",
        "      en_initial_states = encoder.init_states(BATCH_SIZE)\n",
        "\n",
        "      for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "          loss = train_step(model, source_seq, target_seq_in,target_seq_out, en_initial_states)\n",
        "      \n",
        "      ep_list.append(e+1)\n",
        "      loss_list.append(loss.numpy())\n",
        "      print('Epoch {} Loss {:.8f}'.format(e + 1, loss.numpy()))\n",
        "  return encoder, decoder, loss_list, ep_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V68sDlbyVlZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_bleu_score(actual_string, predicted_string):\n",
        "    actual_string = copy.deepcopy(actual_string)\n",
        "    predicted_string = copy.deepcopy(predicted_string)\n",
        "    reference = re.split(\"\\s\",actual_string.strip())\n",
        "    candidate = re.split(\"\\s\",predicted_string.strip())\n",
        "    try:\n",
        "      reference.remove('<eos>')\n",
        "      candidate.remove('<sos>')\n",
        "    except:\n",
        "      pass\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io7wptcmxdfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(xlist,ylist,xname,yname):\n",
        "  x = np.array(xlist)\n",
        "  y = np.array(ylist)\n",
        "  d = {xname: x, yname: y}\n",
        "  data = pd.DataFrame(d)\n",
        "  sns.lineplot(x=xname, y=yname,data = data)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PkvNOsmdCu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction(X,y,model):\n",
        "  for index,line in enumerate(X):\n",
        "    alignment, output = predict(model,line)\n",
        "    print(\"source: \",line)\n",
        "    print(\"actual: \",y[index])\n",
        "    print(\"predicted: \",output)\n",
        "    # print(\"BLEU Score: \",calculate_bleu_score(output,y[index]))\n",
        "    ax = sns.heatmap(alignment[:,0,0,:],linewidths=.2,cmap=\"YlGnBu\")\n",
        "    # print(type(alignment))\n",
        "    # print(alignment[:,0,0,:])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--YEfvR4x_7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "09287293-9744-4a8e-ff9c-df47815d3e5e"
      },
      "source": [
        "attn_type = 'BahdanauAttention'\n",
        "# attn_type = 'LuongAttentionDot'\n",
        "# attn_type = 'LuongAttention'\n",
        "NUM_EPOCHS = 10\n",
        "encoder, decoder, loss_list,epoch_list = train_model(attn_type,NUM_EPOCHS)\n",
        "plot_graph(epoch_list,loss_list,\"Epochs\",\"Loss\")\n",
        "model = {\"encoder\":encoder,\"decoder\":decoder}\n",
        "# get_prediction(X_test,y_in_test)\n",
        "get_prediction(X_train,y_in_train, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f851d7a4978>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f851d7b1b00>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f8571e85390>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "Epoch 1 Loss 2.17370486\n",
            "Epoch 2 Loss 2.08820486\n",
            "Epoch 3 Loss 2.05565739\n",
            "Epoch 4 Loss 2.02970958\n",
            "Epoch 5 Loss 2.00915122\n",
            "Epoch 6 Loss 1.98118615\n",
            "Epoch 7 Loss 1.96889341\n",
            "Epoch 8 Loss 1.93253160\n",
            "Epoch 9 Loss 1.89002788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4S00hyf3oTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}